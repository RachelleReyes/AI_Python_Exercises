{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-88ec8f63a9a4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m     \u001b[1;31m# stacking columns wth all ones in feature matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 104\u001b[1;33m     \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m     \u001b[1;31m# response vector\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\shape_base.py\u001b[0m in \u001b[0;36mhstack\u001b[1;34m(tup)\u001b[0m\n\u001b[0;32m    286\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 288\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    289\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: all the input arrays must have same number of dimensions"
     ]
    }
   ],
   "source": [
    "import csv \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "  \n",
    "  \n",
    "X = np.array([.5,.75,1,1.25,1.5,1.75,1.75,2,2.25,2.5,2.75,3,3.25,3.50,4,4.25,4.5,4.75,5,5.5])\n",
    "\n",
    "  \n",
    "def normalize(X): \n",
    "    ''' \n",
    "    function to normalize feature matrix, X \n",
    "    '''\n",
    "    mins = np.min(X, axis = 0) \n",
    "    maxs = np.max(X, axis = 0) \n",
    "    rng = maxs - mins \n",
    "    norm_X = 1 - ((maxs - X)/rng) \n",
    "    return norm_X \n",
    "  \n",
    "  \n",
    "def logistic_func(beta, X): \n",
    "    ''' \n",
    "    logistic(sigmoid) function \n",
    "    '''\n",
    "    return 1.0/(1 + np.exp(-np.dot(X, beta.T))) \n",
    "  \n",
    "  \n",
    "def log_gradient(beta, X, y): \n",
    "    ''' \n",
    "    logistic gradient function \n",
    "    '''\n",
    "    first_calc = logistic_func(beta, X) - y.reshape(X.shape[0], -1) \n",
    "    final_calc = np.dot(first_calc.T, X) \n",
    "    return final_calc \n",
    "  \n",
    "  \n",
    "def cost_func(beta, X, y): \n",
    "    ''' \n",
    "    cost function, J \n",
    "    '''\n",
    "    log_func_v = logistic_func(beta, X) \n",
    "    y = np.squeeze(y) \n",
    "    step1 = y * np.log(log_func_v) \n",
    "    step2 = (1 - y) * np.log(1 - log_func_v) \n",
    "    final = -step1 - step2 \n",
    "    return np.mean(final) \n",
    "  \n",
    "  \n",
    "def grad_desc(X, y, beta, lr=.01, converge_change=.001): \n",
    "    ''' \n",
    "    gradient descent function \n",
    "    '''\n",
    "    cost = cost_func(beta, X, y) \n",
    "    change_cost = 1\n",
    "    num_iter = 1\n",
    "      \n",
    "    while(change_cost > converge_change): \n",
    "        old_cost = cost \n",
    "        beta = beta - (lr * log_gradient(beta, X, y)) \n",
    "        cost = cost_func(beta, X, y) \n",
    "        change_cost = old_cost - cost \n",
    "        num_iter += 1\n",
    "      \n",
    "    return beta, num_iter  \n",
    "  \n",
    "  \n",
    "def pred_values(beta, X): \n",
    "    ''' \n",
    "    function to predict labels \n",
    "    '''\n",
    "    pred_prob = logistic_func(beta, X) \n",
    "    pred_value = np.where(pred_prob >= .5, 1, 0) \n",
    "    return np.squeeze(pred_value) \n",
    "  \n",
    "  \n",
    "def plot_reg(X, y, beta): \n",
    "    ''' \n",
    "    function to plot decision boundary \n",
    "    '''\n",
    "    # labelled observations \n",
    "    x_0 = X[np.where(y == 0.0)] \n",
    "    x_1 = X[np.where(y == 1.0)] \n",
    "      \n",
    "    # plotting points with diff color for diff label \n",
    "    plt.scatter([x_0[:, 1]], [x_0[:, 2]], c='b', label='y = 0') \n",
    "    plt.scatter([x_1[:, 1]], [x_1[:, 2]], c='r', label='y = 1') \n",
    "      \n",
    "    # plotting decision boundary \n",
    "    x1 = np.arange(0, 1, 0.1) \n",
    "    x2 = -(beta[0,0] + beta[0,1]*x1)/beta[0,2] \n",
    "    plt.plot(x1, x2, c='k', label='reg line') \n",
    "  \n",
    "    plt.xlabel('x1') \n",
    "    plt.ylabel('x2') \n",
    "    plt.legend() \n",
    "    plt.show() \n",
    "      \n",
    "  \n",
    "      \n",
    "if __name__ == \"__main__\": \n",
    "    # load the dataset \n",
    "    X = np.array([.5,.75,1,1.25,1.5,1.75,1.75,2,2.25,2.5,2.75,3,3.25,3.50,4,4.25,4.5,4.75,5,5.5])\n",
    "      \n",
    "    # stacking columns wth all ones in feature matrix \n",
    "    X = np.hstack((np.matrix(np.ones(X.shape[0])).T, X)) \n",
    "  \n",
    "    # response vector \n",
    "    y = dataset[:, -1] \n",
    "  \n",
    "    # initial beta values \n",
    "    beta = np.matrix(np.zeros(X.shape[1])) \n",
    "  \n",
    "    # beta values after running gradient descent \n",
    "    beta, num_iter = grad_desc(X, y, beta) \n",
    "  \n",
    "    # estimated beta values and number of iterations \n",
    "    print(\"Estimated regression coefficients:\", beta) \n",
    "    print(\"No. of iterations:\", num_iter) \n",
    "  \n",
    "    # predicted labels \n",
    "    y_pred = pred_values(beta, X) \n",
    "      \n",
    "    # number of correctly predicted labels \n",
    "    print(\"Correctly predicted labels:\", np.sum(y == y_pred)) \n",
    "      \n",
    "    # plotting regression line \n",
    "    plot_reg(X, y, beta) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
