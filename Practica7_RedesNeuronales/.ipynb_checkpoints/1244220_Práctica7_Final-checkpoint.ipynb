{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2 align=\"center\">\n",
    "<FONT \"> UNIVERSIDAD AUTÓNOMA DE BAJA CALIFORNIA</FONT><br>\n",
    "<img src=\"http://imageninstitucional.uabc.mx/sites/default/files/inline-images/Escudo_0.png\" width=\"200\"></h2>\n",
    "\n",
    "\n",
    "<h3 align=\"center\"><FONT COLOR=\"black\"> Reyes Udasco Rachelle Nerie</FONT><br></h3>\n",
    "<h3 align=\"center\"><FONT COLOR=\"black\"> Práctica 7</FONT><br></h3>\n",
    "<h3 align=\"center\"><FONT COLOR=\"black\"> Fecha de entrega: 23 de mayo del 2019</FONT><br></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica 7: Redes Neuronales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redes Neuronales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pasos para la programación del red neuronal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"justify\">\n",
    "**1. Inicializar red.** <br>\n",
    "Crear una red neuronal lista para el entrenamiento.\n",
    "Defina el número de entradas, el número de neuronas que se deben tener en la capa oculta y el número de salidas.<br><br>\n",
    "**2. Propagar hacia adelante.**\n",
    "\n",
    "Calcule una salida de una red neuronal mediante la propagación de una señal de entrada a través de cada capa hasta que la capa de salida genere sus valores.\n",
    "\n",
    "Es la técnica que necesitaremos para generar predicciones durante el entrenamiento que deberá ser corregida, y es el método que necesitaremos después de que la red esté capacitada para hacer predicciones sobre nuevos datos.\n",
    "\n",
    "a. Activación de la neurona.\n",
    "Calcula la activación de una neurona dada una entrada.\n",
    "La activación neuronal se calcula como la suma ponderada de las entradas<br>\n",
    "\n",
    "b. Transferencia de neuronas.\n",
    "Una vez que se activa una neurona, debemos transferir la activación para ver qué es realmente la salida de la neurona.\n",
    "\n",
    "Se pueden utilizar diferentes funciones de transferencia. Es tradicional usar la función de activación sigmoide, pero también puede usar la función tanh (tangente hiperbólica) para transferir salidas. <br>\n",
    "\n",
    "c. Propagación hacia adelante.\n",
    "\n",
    "Trabajamos a través de cada capa de nuestra red calculando las salidas para cada neurona. Todas las salidas de una capa se convierten en entradas a las neuronas en la siguiente capa.\n",
    "\n",
    "\n",
    "**3. Propagación hacia atrás.**\n",
    "\n",
    "El algoritmo de backpropagation se llama así por la forma en que se entrenan los pesos.\n",
    "\n",
    "a. Derivado de transferencia.\n",
    "Dado un valor de salida de una neurona, necesitamos calcular su pendiente, por lo que es necesario calcular la derivada de la función. <br>\n",
    "b. Error Backpropagation.\n",
    "El primer paso es calcular el error para cada neurona de salida, esto nos dará nuestra señal de error (entrada) para propagarnos hacia atrás a través de la red.\n",
    "\n",
    "\n",
    "**4. Entrenar red**\n",
    "\n",
    "La red se entrena usando el descenso de gradiente estocástico.\n",
    "Esto implica múltiples iteraciones para exponer un conjunto de datos de entrenamiento a la red y para cada fila de datos avanzar propagando las entradas, volviendo a propagar el error y actualizando los pesos de la red.\n",
    "\n",
    "a. Actualizar pesos.\n",
    "Una vez que se calculan los errores para cada neurona en la red a través del método anterior de propagación, se pueden usar para actualizar los pesos.<br>\n",
    "b. Entrenar red\n",
    "\n",
    "**5. Predicción**\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desarrollo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset proporcionado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instancias: 4 Atributos: 2\n"
     ]
    }
   ],
   "source": [
    "inputs = np.array([\n",
    "[4.7,6.0],\n",
    "[6.1,3.9],\n",
    "[2.9,4.2],\n",
    "[7.0,5.5]])\n",
    "\n",
    "targets = np.array([\n",
    "[3.52,4.02],\n",
    "[5.43,6.23],\n",
    "[4.95,5.76],\n",
    "[4.70,4.28]])\n",
    "\n",
    "#Obtener dimensiones de la entrada\n",
    "instancias,atributos = inputs.shape\n",
    "q = instancias\n",
    "print(\"Instancias: \" + str(instancias),\"Atributos: \"+ str(atributos))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Propagacion hacia adelante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Clase de Regresion Logistica\n",
    "class LogisticRegressionGD():\n",
    "    def __init__(self, max_iter=1000, eta=0.5, max_error=0.1):\n",
    "        self.w = 0\n",
    "        self.max_iter = max_iter\n",
    "        self.eta = eta\n",
    "        self.max_error = max_error\n",
    "    \n",
    "    # Funcion que calcula el error\n",
    "    def CrossEntropy(self, x, y, hx):\n",
    "        return (np.matmul(-y.T,np.log(hx))-np.matmul((1 -y.T),np.log(1-hx)))/len(x)\n",
    "    \n",
    "    # Funcion que realiza el ajuste de parametros\n",
    "    def fit(self,X,Y,w):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        n = len(X)\n",
    "        for i in range(self.max_iter):\n",
    "            hx = self.eval(X, w)\n",
    "            w = w - self.eta * np.matmul(X.T, (hx-Y))/n;\n",
    "            error = self.CrossEntropy(X,Y,hx)\n",
    "            if error <= self.max_error:\n",
    "                break\n",
    "        print(\"Error = {}\".format(error))\n",
    "        return w\n",
    "    \n",
    "    # Funcion hipotesis/sigmoide\n",
    "    def eval(self,x,w):\n",
    "        return 1/(1+np.exp(-np.matmul(x,w)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Red_Neuronal(object):\n",
    "    def __init__(self, max_iter=1000, eta=0.5, max_error=0.1):\n",
    "        self.max_iter = max_iter\n",
    "        self.eta = eta\n",
    "        self.max_error = max_error\n",
    "        \n",
    "    # Funcion de transferencia\n",
    "    def funcionTransferencia(activacion):\n",
    "        return 1/(1+np.exp(-activacion))\n",
    "\n",
    "    # Funcion que realiza la activación de la neruona con los pesos y entradas\n",
    "    def activar(pesos, entradas):\n",
    "        return np.dot(pesos,entradas)\n",
    "\n",
    "    def sse(target, predicted):\n",
    "        return np.sum(np.power(target-predicted,2))\n",
    "\n",
    "    def propagacionAdelante(inputs,pesos):\n",
    "        a0 = inputs.T\n",
    "        a0_ = np.concatenate([a0,np.ones((1,q))],axis=0)\n",
    "\n",
    "        z1 =  activar(pesos[0],a0_)\n",
    "        a1 =  funcionTransferencia(z1)\n",
    "        a1_ = np.concatenate([self.a1,np.ones((1,q))],axis=0)\n",
    "\n",
    "        z2 =  activar(pesos[1],a1_)\n",
    "        a2 =  funcionTransferencia(z2)\n",
    "        a2_ = np.concatenate([a2,np.ones((1,q))],axis=0)\n",
    "\n",
    "        z3 = activar(pesos[2],a2_)\n",
    "        a3 = funcionTransferencia(z3)\n",
    "\n",
    "        return a3\n",
    "\n",
    "    # Derivada de la función de transferencia\n",
    "    def dervidadaTransferencia(salida):\n",
    "        return salida * (1-salida)\n",
    "\n",
    "    def propagacionAtras(self, pesos,z1,z2,z3):\n",
    "        \n",
    "        self.pesos = pesos\n",
    "        self.z1 = z1\n",
    "        self.z2 = z2\n",
    "        self.z3 = z3\n",
    "        \n",
    "        deltaK = np.dot(-2*np.exp(1),dervidadaTransferencia(z3))\n",
    "        deltaJ = np.dot(np.dot(pesos[2][:,0:3].T,deltaK),dervidadaTransferencia(z2).T)\n",
    "        deltaI = np.dot(np.dot(pesos[1][:,0:2].T,deltaJ).T,dervidadaTransferencia(z1))\n",
    "    \n",
    "        w3New = np.dot(deltaK,a3)\n",
    "        w2New = np.dot(deltaJ,a2)\n",
    "        w1New = np.dot(deltaI,a1)\n",
    "        pesosNew = [w1New,w2New,w3New]\n",
    "        \n",
    "        return pesosNew\n",
    "\n",
    "    def fit(entradas, targets, pesos):\n",
    "        self.entradas = entradas\n",
    "        self.targets = targets\n",
    "        self.pesos = pesos\n",
    "        \n",
    "        for i in range(self.max_iter):\n",
    "            salida = propagacionAdelante(inputs,pesos)\n",
    "            pesos = propagacionAtras(pesos,z1,z2,z3)\n",
    "            error =  sse = np.sum(np.power(np.subtract(targets.T,a3New),2))\n",
    "                \n",
    "            if error <= self.max_error:\n",
    "                break\n",
    "            print(\"Error = {}\".format(error))\n",
    "            return pesos\n",
    "\n",
    "    def predecir(self):\n",
    "        print (\"Valores prdecidos: \");\n",
    "        print (\"Entrada: \\n\" + str(inputs));\n",
    "        #print (\"Salida: \\n\" + str(self.propagacionAdelante(inputs,pesos)));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrada: \n",
      "[[4.7 6. ]\n",
      " [6.1 3.9]\n",
      " [2.9 4.2]\n",
      " [7.  5.5]]\n",
      "Salida actual: \n",
      "[[3.52 4.02]\n",
      " [5.43 6.23]\n",
      " [4.95 5.76]\n",
      " [4.7  4.28]]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "fit() takes 3 positional arguments but 4 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-d2d82f103e7d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;31m# print (\"Error: \\n\" + str(sse(targets,a)))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;31m# print (\"\\n\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0mRN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpesos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: fit() takes 3 positional arguments but 4 were given"
     ]
    }
   ],
   "source": [
    "RN = Red_Neuronal()\n",
    "# Valores de los pesos\n",
    "w1_ = np.random.rand(2,3)\n",
    "w2_ = np.random.rand(3,3) \n",
    "w3_ = np.random.rand(2,4)\n",
    "pesos = [w1_,w2_,w3_]\n",
    "\n",
    "#for i in range(1000): # trains the NN 1,000 times\n",
    "#print (\"# \" + str(i) + \"\\n\")\n",
    "\n",
    "print (\"Entrada: \\n\" + str(inputs))\n",
    "print (\"Salida actual: \\n\" + str(targets))\n",
    "# a = RN.propagacionAdelante(inputs,pesos)\n",
    "# a = RN.propagacionAdelante(inputs,pesos)\n",
    "# print (\"Salida predecida: \\n\" + str(a))\n",
    "# error = np.subtract(targets.T,a)\n",
    "# sse = np.sum(np.power(error,2))\n",
    "# print (\"Error: \\n\" + str(sse(targets,a)))\n",
    "# print (\"\\n\")\n",
    "RN.fit(inputs, targets,pesos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.48404524 0.00322434 0.08286674]\n",
      " [0.045819   0.47777709 0.8721858 ]]\n",
      "[[0.96843367 0.42827242 0.65159738]\n",
      " [0.43305112 0.13985425 0.60392657]\n",
      " [0.83772433 0.36933943 0.20275669]]\n",
      "[[0.32028459 0.95906764 0.11651607 0.81412075]\n",
      " [0.98476896 0.36580466 0.68230751 0.01585205]]\n"
     ]
    }
   ],
   "source": [
    "def funcionTransferencia(activacion):\n",
    "    return 1/(1+np.exp(-activacion))\n",
    "\n",
    "# Funcion que realiza la activación de la neruona con los pesos y entradas\n",
    "def activar(pesos, entradas):\n",
    "    return np.dot(pesos,entradas)\n",
    "\n",
    "def sse(target, predicted):\n",
    "    return np.sum(np.power(target-predicted,2))\n",
    "\n",
    "def propagacionAdelante(entradas,instancias,pesos):\n",
    "    entradasAumentadas = []\n",
    "    for i in range(instancias):\n",
    "        if i>0 & i<(instancias-2):\n",
    "            z = activar(pesos[i-1],entradasAumentadas)\n",
    "            entradas = funcionTransferencia(z)\n",
    "            entradasAumentadas = np.concatenate([entradas,np.ones((1,instancias))],axis=0)\n",
    "        elif i == 0:\n",
    "            entradasAumentadas = np.concatenate([entradas,np.ones((1,instancias))],axis=0)\n",
    "    return entradas\n",
    "\n",
    "w1_ = np.random.rand(2,3)\n",
    "print(w1_)\n",
    "w2_ = np.random.rand(3,3) \n",
    "print(w2_)\n",
    "w3_ = np.random.rand(2,4)\n",
    "print(w3_)\n",
    "pesos = [w1_,w2_,w3_]\n",
    "\n",
    "a0 = inputs.T\n",
    "a0_ = np.concatenate([a0,np.ones((1,q))],axis=0)\n",
    "\n",
    "z1 =  activar(pesos[0],a0_)\n",
    "a1 =  funcionTransferencia(z1)\n",
    "a1_ = np.concatenate([a1,np.ones((1,q))],axis=0)\n",
    "\n",
    "z2 =  activar(pesos[1],a1_)\n",
    "a2 =  funcionTransferencia(z2)\n",
    "a2_ = np.concatenate([a2,np.ones((1,q))],axis=0)\n",
    "\n",
    "z3 = activar(pesos[2],a2_)\n",
    "a3 = funcionTransferencia(z3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrada: \n",
      "[[4.7 6. ]\n",
      " [6.1 3.9]\n",
      " [2.9 4.2]\n",
      " [7.  5.5]]\n",
      "Salida actual: \n",
      "[[3.52 4.02]\n",
      " [5.43 6.23]\n",
      " [4.95 5.76]\n",
      " [4.7  4.28]]\n",
      "Salida predecida: \n",
      "[[0.87137625 0.87178748 0.8698107  0.87213402]\n",
      " [0.84495949 0.84577539 0.84157393 0.84653907]]\n",
      "Error: \n",
      "134.14333763353864\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (\"Entrada: \\n\" + str(inputs))\n",
    "print (\"Salida actual: \\n\" + str(targets))\n",
    "print (\"Salida predecida: \\n\" + str(a3))\n",
    "error = np.subtract(targets.T,a3)\n",
    "sse = np.sum(np.power(error,2))\n",
    "print (\"Error: \\n\" + str(sse))\n",
    "print (\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.49813557 9.55466463 9.28565891 9.60253546]\n",
      " [6.41223525 6.49358677 6.08279037 6.57043641]]\n",
      "[[-69.54656235  -5.77914633 -16.29573775]\n",
      " [-85.16868189  -7.07066369 -19.94091621]\n",
      " [-40.74204961  -3.38639625  -9.54835527]]\n",
      "[[1115.85177197 1208.52891754  447.60859603 1813.03040601]\n",
      " [  92.7101192   100.40837466   37.18976326  150.63270774]\n",
      " [ 261.4266148   283.13529617  104.86855301  424.75951859]]\n",
      "[[9.49813557 6.41223525]\n",
      " [9.55466463 6.49358677]\n",
      " [9.28565891 6.08279037]\n",
      " [9.60253546 6.57043641]]\n",
      "[[0.87137625 0.87178748 0.8698107  0.87213402]\n",
      " [0.84495949 0.84577539 0.84157393 0.84653907]]\n",
      "[[32.50688842 32.5918791  32.16585415 32.66963884]\n",
      " [21.91882342 21.97560741 21.69112341 22.02750751]]\n",
      "[[ -85.60641401  -88.20088164  -78.66479571  -89.43691531]\n",
      " [-104.81420839 -107.9916522   -96.31349336 -109.50516579]\n",
      " [ -50.15303474  -51.67291302  -46.08644431  -52.39703237]\n",
      " [   2.89626074    2.90794893    2.77069638    2.94892803]]\n",
      "[[0.48404524 0.00322434 0.08286674]\n",
      " [0.045819   0.47777709 0.8721858 ]]\n"
     ]
    }
   ],
   "source": [
    "# Derivada de la función de transferencia\n",
    "def dervidadaTransferencia(salida):\n",
    "    return salida * (1-salida)\n",
    "\n",
    "deltaK = np.dot(-2*np.exp(1),dervidadaTransferencia(z3))\n",
    "print(deltaK)\n",
    "deltaJ = np.dot(np.dot(w3_[:,0:3].T,deltaK),dervidadaTransferencia(z2).T)\n",
    "print(deltaJ)\n",
    "deltaI = np.dot(np.dot(w2_[:,0:2].T,deltaJ).T,dervidadaTransferencia(z1))\n",
    "print(deltaI)\n",
    "\n",
    "#Actualizacion de pesos\n",
    "w3New = np.dot(deltaK,a2_)  \n",
    "print(deltaK.T)\n",
    "print(a3)\n",
    "print(w3New)\n",
    "temp = np.concatenate([deltaJ,np.ones((1,3))],axis=0)\n",
    "w2New = np.dot(temp,a1_)\n",
    "print(w2New)\n",
    "w1New = w1_\n",
    "print(w1New)\n",
    "pesosNew = [w1New,w2New,w3New]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.49813557 9.55466463 9.28565891 9.60253546]\n",
      " [6.41223525 6.49358677 6.08279037 6.57043641]]\n",
      "[[-69.54656235  -5.77914633 -16.29573775]\n",
      " [-85.16868189  -7.07066369 -19.94091621]\n",
      " [-40.74204961  -3.38639625  -9.54835527]]\n",
      "[[1115.85177197 1208.52891754  447.60859603 1813.03040601]\n",
      " [  92.7101192   100.40837466   37.18976326  150.63270774]\n",
      " [ 261.4266148   283.13529617  104.86855301  424.75951859]]\n"
     ]
    }
   ],
   "source": [
    "deltaK = np.dot(-2*np.exp(1),dervidadaTransferencia(z3))\n",
    "print(deltaK)\n",
    "deltaJ = np.dot(np.dot(w3_[:,0:3].T,deltaK),dervidadaTransferencia(z2).T)\n",
    "print(deltaJ)\n",
    "deltaI = np.dot(np.dot(w2_[:,0:2].T,deltaJ).T,dervidadaTransferencia(z1))\n",
    "print(deltaI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13.69452878 13.70366649 13.65794997 13.71185485]\n",
      " [13.81252559 13.82175292 13.77558286 13.83002299]\n",
      " [13.23101408 13.23979562 13.19588327 13.24765875]\n",
      " [13.91917393 13.92848365 13.88189608 13.936829  ]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (4,4) and (3,4) not aligned: 4 (dim 1) != 3 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-fcf358b20307>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mw3New\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdeltaK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ma3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw3New\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mw2New\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdeltaJ\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ma2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw2New\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mw1New\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdeltaI\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ma1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (4,4) and (3,4) not aligned: 4 (dim 1) != 3 (dim 0)"
     ]
    }
   ],
   "source": [
    "w3New = np.dot(deltaK.T,a3)\n",
    "print(w3New)\n",
    "w2New = np.dot(deltaJ,a2)\n",
    "print(w2New)\n",
    "w1New = np.dot(deltaI,a1.T)\n",
    "print(w1New)\n",
    "pesosNew = [w1New,w2New,w3New]\n",
    "pesos = [w1New,w2New,w3New]\n",
    "\n",
    "a0New = inputs.T\n",
    "a0_New = np.concatenate([a0New,np.ones((1,q))],axis=0)\n",
    "\n",
    "z1New =  activar(pesos[0].T,a0_New)\n",
    "a1New =  funcionTransferencia(z1New)\n",
    "a1_New = np.concatenate([a1New,np.ones((1,q))],axis=0)\n",
    "\n",
    "z2New =  activar(pesos[1].T,a1_New)\n",
    "a2New =  funcionTransferencia(z2New)\n",
    "a2_New = np.concatenate([a2New,np.ones((1,q))],axis=0)\n",
    "\n",
    "z3New = activar(pesos[2],a2_New.T)\n",
    "a3New = funcionTransferencia(z3New)\n",
    "\n",
    "print (\"Entrada: \\n\" + str(inputs))\n",
    "print (\"Salida actual: \\n\" + str(targets))\n",
    "print (\"Salida predecida: \\n\" + str(a3))\n",
    "error = np.subtract(targets.T,a3New)\n",
    "sse = np.sum(np.power(error,2))\n",
    "print (\"Error: \\n\" + str(sse))\n",
    "print (\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusión "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"justify\">\n",
    "La programación de este ejemplo en específico no fue tan sencillo como se esperaba, no por las funciones en sí que necesitan ser programadas sino por el almacenamiento y la concatencacion de los resultados siendo éstos de diferentes tamaños. Con esto dicho, si fue posible crear las funciones de la propagación hacia adeltante y atrás como se presentó en esta práctica sólo regresando el resultado final y no todos los valores obtenidos durante el proceso, lo cual es ideal. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Referencias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Brownlee, J. (2016) How to Implement the Backpropagation Algorithm From Scratch In Python. Obtenido del Sitio web: https://machinelearningmastery.com/implement-backpropagation-algorithm-scratch-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
